---
name: sbux:proposal
description: 生成提案文档。当用户需要规划新功能、生成需求文档、设计文档、API文档、测试用例时使用。触发词：提案、需求、设计、规划功能、新功能。
---

# /sbux:proposal - 生成提案文档

## 描述

分析用户需求，生成完整的提案文档，包括需求、设计、API、测试用例和任务清单。

**模式**：Plan 模式（需要人机交互确认）

---

## 执行流程

### Step 0: 项目识别

根据项目自动识别技术栈，如果无法识别（或者空项目），则引导用户一起设计技术栈。

---

### Step 1: 需求澄清与深度分析

1. 分析用户输入的需求描述
2. 识别以下信息：
   - 核心功能点
   - 业务场景
   - 可能的约束条件
3. **深度分析**：识别所有潜在不确定项，分类整理：
   - **功能边界**：哪些做/哪些不做
   - **技术选型**：算法、框架、方案选择
   - **业务规则**：校验规则、流程分支、边界条件
   - **非功能需求**：性能指标、安全要求、可用性要求
4. 输出待确认项清单，**等待进入 Step 1.5 批量确认**

---

### Step 1.5: 批量确认

基于 Step 1 的分析结果，使用 `AskUserQuestion` 工具批量确认不确定项：

1. **整理待确认清单**：将所有不确定项按类别分组
2. **分批询问**：使用 AskUserQuestion（每次最多 4 个问题）
3. **多轮确认**：如问题超过 4 个，分多轮询问直到全部确认
4. **记录决策**：将用户的确认结果作为后续生成文档的输入

**注意**：必须等待所有问题确认后才能进入 Step 1.6。

---

### Step 1.6: 选择生成模式

使用 `AskUserQuestion` 询问用户文档生成方式：

**问题**：请选择文档生成模式
**选项**：
1. **一次性生成（推荐）** - 连续生成所有 5 个文档后统一展示
2. **逐个确认** - 每生成一个文档后暂停，确认后再生成下一个

选择说明：
- 一次性生成：适合需求清晰、想快速完成的场景
- 逐个确认：适合需要边生成边调整的场景

---

### Step 2: 确定 proposal-id 并创建分支

1. **检查工作区状态**：
   - 运行 `git status --porcelain`
   - 如有未提交的更改，提示用户先处理（commit 或 stash）

2. **确定 proposal-id**：
   - 序号：检查 `.proposal/` 目录，计算下一个序号（001, 002...）
   - feature-name：基于澄清后的需求提取关键词，转换为 kebab-case
   - 格式：`{序号}-{feature-name}`
   - 示例：`003-user-auth`

3. **创建并切换特性分支**：
   - 分支名与 proposal-id 一致：`feature/{proposal-id}`
   - 运行 `git checkout -b feature/{proposal-id}`
   - 告知用户：「已创建特性分支：feature/xxx-xxx」

---

### Step 3: 创建提案目录

使用 Step 2 确定的 proposal-id 创建目录：

```bash
mkdir -p .proposal/{proposal-id}
# 例如：mkdir -p .proposal/003-user-auth
```

---

### Step 4: 生成需求文档 (1-requirements.md)

读取同目录下的 `requirements.template.md` 模板，生成需求文档。

**必须包含的内容**：

1. **功能概述**：一句话描述
2. **功能要求 (FR)**：
   - 拆解为具体的功能点
   - 每个功能点有明确的验收标准
   - 标注优先级 (P0/P1/P2)
3. **非功能要求 (NFR)**：
   - 性能指标
   - 安全要求
   - 可用性要求
4. **约束与假设**

**质量检查**：
- [ ] 功能要求覆盖用户需求的所有点
- [ ] 每个 FR 都有验收标准
- [ ] NFR 包含性能、安全指标

---

### Step 5: 生成设计文档 (2-design.md)

读取同目录下的 `design.template.md` 模板，生成设计文档。

**必须包含的内容**：

1. **设计概述**：目标和范围
2. **架构设计**：
   - 涉及的层和组件
   - 组件交互关系
3. **数据模型**：
   - 后端：Entity/Model 定义
   - 前端：TypeScript interface/type
4. **核心流程**：
   - 主流程图
   - 异常处理
5. **技术决策**：备选方案和最终决定
6. **安全考虑**
7. **性能考虑**

**质量检查**：
- [ ] 架构图与项目类型匹配
- [ ] 数据模型完整
- [ ] 核心流程明确
- [ ] 技术决策有理由
- [ ] 异常处理已设计

---

### Step 6: 生成 API 文档 (3-api-spec.md)

读取同目录下的 `api-spec.template.md` 模板，生成 API 接口文档。

对每个端点设计：

1. **基本信息**
   - HTTP 方法 (GET/POST/PUT/DELETE)
   - URL 路径（遵循 RESTful 规范）
   - 功能描述

2. **请求参数**
   - Path 参数
   - Query 参数
   - Body 参数
   - 每个参数的类型、是否必填、校验规则

3. **响应格式**
   - 成功响应结构
   - 响应字段说明

4. **错误码**
   - 可能的错误场景
   - 对应的错误码和错误信息

**质量检查**：
- [ ] URL 路径符合 RESTful 规范
- [ ] 所有参数都有类型和说明
- [ ] 必填/选填标注清晰
- [ ] 校验规则明确
- [ ] 所有可能的错误码都已列出
- [ ] 有请求/响应示例
- [ ] 与项目现有 API 风格一致

---

### Step 7: 生成测试用例 (4-test-cases.md)

**Step 7.1: 确认测试环境配置**

在生成测试用例之前，首先识别系统的环境配置：

1. **自动扫描**：根据项目技术栈自动识别配置文件（例如：Java 的 `application*.yml`/`properties`；Node.js 的 `.env` / `config/default.json`；Python 的 `settings.py` / `.env`；Go 的 `config.yaml` 等）。
2. **用户选择**：使用 `AskUserQuestion` 让用户选择测试使用的配置：
   - **问题**：请选择测试环境配置文件
   - **选项**：
      - [扫描到的配置文件列表]
      - "AI 生成专用测试配置" (自动生成测试专用配置)
      - "手动指定" (用户输入路径)

3. **配置解析**：
   - 解析选中的配置文件，提取数据库、缓存、消息队列等关键基础设施的连接信息摘要（注意脱敏）。
   - 如果选择 "AI 生成专用测试配置"，则基于当前技术栈的最佳实践（如 TestContainers, H2, SQLite, Minikube 等）生成一份标准的测试配置内容。

**Step 7.2: 生成文档**

读取同目录下的 `test-cases.template.md` 模板，生成测试用例文档。并将选中的环境配置信息填入模板的 `{{TEST_ENV_CONFIG}}` 等字段。

**特别原则**：
- **拒绝 Mock**：测试用例必须基于真实数据库/中间件运行（使用 TestContainers 或 真实环境），严禁 Mock 数据库和内部组件。只有不可控的外部第三方服务才允许 Mock。
- **全链路覆盖**：确保测试用例能走完实际的代码逻辑路径，验证数据库和缓存的真实状态变更。

**集成测试 (IT-*)**：
- 测试 Service/Component 层业务逻辑
- 必须基于真实数据库交互
- 覆盖正常路径、异常路径、边界条件
- 包含完整的数据准备(Given)和清理(Teardown)步骤

**接口测试 (AT-*)**：
- 测试 Controller 层接口
- 模拟真实的 HTTP 请求调用
- 验证响应数据及后端存储状态的正确性

**质量检查**：
- [ ] 能够直接在真实/容器化数据库上运行
- [ ] 没有任何数据库操作被 Mock
- [ ] 验证逻辑包含数据库状态检查
- [ ] 覆盖所有核心业务分支
- [ ] 包含数据清理机制，保证可重复执行

---

### Step 8: 生成任务清单 (5-tasks.md)

读取同目录下的 `tasks.template.md` 模板，生成任务清单。

**任务批次划分（由系统自动设计）**：

编码任务（C-*）和测试任务（T-*）**分别独立划分批次**，编码阶段全部完成后再执行测试阶段。

1. **生成任务列表**：
   - 列出所有编码任务（C-*）
   - 列出所有测试任务（T-*）
   - 每个任务包含：ID、描述、目标文件、**依赖任务**
   - 测试任务只记录 T-* 之间的依赖，不记录对 C-* 的依赖（因为编码阶段已全部完成）

2. **依赖关系分析**：
   - 文件依赖：A 文件 import B → A 依赖 B
   - 类型依赖：使用某类型 → 依赖该类型定义
   - 接口依赖：调用某方法 → 依赖该方法所在类

3. **自动批次计算**（编码和测试分别计算）：
   - 构建依赖图，检测循环依赖
   - 使用拓扑排序计算批次
   - 无依赖任务 → Batch-1
   - 仅依赖 Batch-1 的任务 → Batch-2
   - 以此类推

4. **批次划分原则**：
   - **编码和测试独立**：C-* 任务和 T-* 任务各自独立划分批次
   - **批次间单向依赖**：Batch-N 只能依赖 Batch-1 ~ Batch-(N-1)
   - **无循环依赖**：任务依赖图必须是 DAG
   - **最小批次数**：满足依赖约束的前提下，尽量减少批次数量
   - **批次内顺序执行**：同批次内有依赖的任务按依赖顺序排列
   - **适当拆分批次**：同一批次内修改的文件不宜过多，避免上下文太长导致遗漏

5. **批次命名**：使用简单序号 Batch-1、Batch-2、Batch-3...（无硬编码层级名称）

**验证任务**：保持原有结构，不按批次划分。

**批次拆分示例**：

```
编码任务:
- C-1: 创建 UserDTO        (depends_on: [])
- C-2: 创建 UserEntity     (depends_on: [])
- C-3: 创建 UserRepository (depends_on: [C-2])
- C-4: 创建 UserService    (depends_on: [C-1, C-3])
- C-5: 创建 UserController (depends_on: [C-1, C-4])

测试任务:
- T-1: UserService 测试    (depends_on: [])
- T-2: UserController 测试 (depends_on: [T-1])

结果:
一、编码任务:
  Batch-1: [C-1, C-2]     # 无依赖
  Batch-2: [C-3]          # 依赖 Batch-1
  Batch-3: [C-4]          # 依赖 Batch-1, Batch-2
  Batch-4: [C-5]          # 依赖 Batch-1, Batch-3

二、测试任务:
  Batch-1: [T-1]          # 无依赖
  Batch-2: [T-2]          # 依赖 Batch-1

三、验证任务:
├── V-1: 构建检查
├── V-2: 集成测试
├── V-3: 接口测试
└── V-4: 全量测试
```

---

### Step 4-8 执行模式说明

根据用户在 Step 1.6 选择的生成模式，执行 Step 4-8：

**如果选择"一次性生成"**：保持现有行为，连续生成 Step 4 → Step 8，无需中间确认。

**如果选择"逐个确认"**：每个 Step 完成后增加确认环节：

每个文档生成后，使用 `AskUserQuestion` 询问：

**问题**：已生成 {文档名称}，请确认是否继续
**选项**：
1. **继续生成下一个** - 继续生成下一个文档
2. **生成剩余所有文档** - 切换为一次性生成模式，连续生成剩余文档
3. **查看并调整** - 暂停，待用户反馈后继续
4. **停止生成** - 中止流程，保留已生成的文档

注意：
- 如果选择"继续生成下一个"，生成下一个文档后继续询问
- 如果选择"生成剩余所有文档"，后续文档将连续生成，不再逐个确认
- 如果选择"查看并调整"，等待用户反馈后再继续
- 如果选择"停止生成"，显示已完成状态并终止流程

---

### 中途停止处理

如果用户在逐个确认模式下选择"停止生成"，显示已完成状态：

```
⏸️ 提案生成已停止：{proposal-id}

📂 已生成文档：
├── 1-requirements.md ✅ / (未生成)
├── 2-design.md ✅ / (未生成)
├── 3-api-spec.md ✅ / (未生成)
├── 4-test-cases.md ✅ / (未生成)
└── 5-tasks.md ✅ / (未生成)

🌿 特性分支：feature/{proposal-id}

💡 后续操作：
- 继续生成：重新运行 /sbux:proposal [需求描述]
- 手动补充：直接编辑 .proposal/{proposal-id}/ 下的文件
- 执行实现：运行 /sbux:apply {proposal-id}（需先补全所有文档）
```

---

## 输出

完成后显示：

```
✅ 提案生成完成：{序号}-{feature-name}

📂 文档目录：.proposal/{序号}-{feature-name}/
├── 1-requirements.md   (需求文档)
├── 2-design.md         (设计文档)
├── 3-api-spec.md       (API文档)
├── 4-test-cases.md     (测试用例)
└── 5-tasks.md          (任务清单)

🌿 特性分支：feature/{序号}-{feature-name}

📋 摘要：
- 功能要求: X 项
- API 接口: X 个
- 测试用例: IT-X 个, AT-X 个
- 开发任务: X 个
```

---

### 询问下一步操作

**第一步**：使用 AskUserQuestion 工具询问「提案已生成完成，您希望如何继续开发？」，选项：

| 选项 | 说明 |
|------|------|
| SubAgent 执行（推荐） | 启动独立 SubAgent 执行 /sbux:apply |
| 直接执行命令 | 当前会话直接执行 /sbux:apply |
| 不执行 | 暂不执行，提示用户查看文档后自行运行 /sbux:apply |

**第二步**：如果用户选择了「SubAgent 执行」，再使用 AskUserQuestion 询问执行模式：

| 选项 | 说明 |
|------|------|
| 同步等待（推荐） | 等待 SubAgent 完成后返回结果 |
| 异步执行 | 后台运行，当前会话可继续其他工作 |

**用户选择后的行为**：

1. **选择「SubAgent 执行」**：
   - 询问同步/异步后：
   - **同步**：使用 Task 工具启动 SubAgent（subagent_type: general-purpose），prompt: `/sbux:apply {proposal-id}`，等待完成返回结果
   - **异步**：设置 run_in_background: true，告知用户可通过 `/tasks` 查看进度

2. **选择「直接执行命令」**：
   - 调用 Skill `sbux:apply`，参数为 `{proposal-id}`
   - 当前会话执行实现

3. **选择「不执行」**：
   - 提示用户查看文档后自行运行 `/sbux:apply`

---

## 参数

- `$ARGUMENTS`：用户需求描述

**示例**：
```
/proposal 实现用户注册功能，支持邮箱和密码注册
/proposal 添加订单查询接口，支持按时间范围和状态筛选
```

---

## 注意事项

1. **不要猜测**：不确定的内容在 Step 1.5 中向用户确认
2. **参考现有代码**：保持与项目风格一致
3. **渐进式生成**：每个文档生成后可以与用户确认
4. **质量优先**：宁可多问，不要假设
